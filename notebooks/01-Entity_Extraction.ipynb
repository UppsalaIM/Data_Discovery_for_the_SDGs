{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cda2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original source code by Yuwei Jiang @YuweiJ98, modfiied by David Johnson @djcomlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PyPDF2 import PdfFileReader\n",
    "import glob\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = []\n",
    "# get all the pdf files from the directory\n",
    "for file in glob.glob('../data/sdg7-papers/*.pdf'):\n",
    "    pdf_files.append(file)\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d662b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the texts of a paper\n",
    "def get_paper_text(path):\n",
    "    # convert PDF to images\n",
    "    images = convert_from_path(path)\n",
    "    # create a string to store texts of the whole paper\n",
    "    whole_paper = ''\n",
    "    # iterate each page\n",
    "    for i in range(len(images)):        \n",
    "        page_content = pytesseract.image_to_string(images[i])\n",
    "        whole_paper = whole_paper + ' ' + page_content\n",
    "    return whole_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract sentences containg the word \"data\"\n",
    "def sentences_containing_data(whole_paper):\n",
    "    sentences = whole_paper.split(\".\")\n",
    "    sentences_contain_data = []\n",
    "    for sentence in sentences:\n",
    "        if 'data' in sentence or 'dataset' in sentence:\n",
    "            sentences_contain_data.append(sentence)\n",
    "    return sentences_contain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c094962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different data sources and data types\n",
    "data_sources = ['questionnaire','interview','survey','census','focus group',\n",
    "'FAO', 'FAOSTAT', 'Food and Agriculture organization of the United Nations',\n",
    "'UN', 'United Nations',\n",
    "'SDSN', 'Sustainable Development Solutions Network',\n",
    "'UNESCO', 'United Nations Educational, Scientific and Cultural Organization',\n",
    "'Eurostat',\n",
    "'EDGAR', 'Emissions Database for Global Atmospheric Research',\n",
    "'Copernicus',\n",
    "'ESDAC', 'ES-DAC', 'European Soil Data Center',\n",
    "'World Bank',\n",
    "'Freedom House',\n",
    "'IEA', 'International Energy Agency',\n",
    "'OECD', 'Organisation for Economic Co-operation and Development',\n",
    "'IMF', 'International Monetary Fund',\n",
    "'Global Carbon Atlas',\n",
    "'Global Footprint Network',\n",
    "'SESRIC', 'Statistical, Economic, and Social Research and Training Center for Islamic Countries',\n",
    "'BP Statistical Review of World Energy',\n",
    "'ADB', 'Asian Development Bank',\n",
    "'WHO', 'World Health Organization',\n",
    "'World Pop',\n",
    "'GADM', 'Global Administrative Areas',\n",
    "'Rosstat', 'Federation Federal State Statistics Service',\n",
    "'General Statistics Office',\n",
    "'Central Statistical Office',\n",
    "'National Institute of Statistics',\n",
    "'DOSM', 'Department of Statistics Malaysia',\n",
    "'National Bureau of Statistics of Tanzania',\n",
    "'Ministry of Education and Science of Ukraine',\n",
    "'BGR', 'Federal Institute for Geosciences and Natural Resources',\n",
    "'NPC', 'National Planning Commission',\n",
    "'ANPM', 'National Environmental Protection Agency',\n",
    "'EIA', 'Energy Information Administration',\n",
    "'MDTCC', 'Ministry of Domestic Trade Co-operatives and Consumerism',\n",
    "'NOAA', 'National Oceanic and Atmospheric Administration',\n",
    "'NASA', 'National Aeronautics and Space Administration',\n",
    "'weather','sensor','sensing',\n",
    "'mineral','water','land','electricity','biomass','solar','heat',\n",
    "'satellite imagery','GPS','GIS','OpenStreetMap', 'OSM']\n",
    "\n",
    "# identify all the defined data sources from a sentence\n",
    "def categorise(sentence):\n",
    "    sources = []\n",
    "    sources_string = ''\n",
    "    for key in data_sources:\n",
    "        if key in sentence and key not in sources:\n",
    "            sources.append(key)\n",
    "    sources_string = ','.join(sources)\n",
    "    return sources_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the paper title from pdf metadata\n",
    "def get_paper_title(path):\n",
    "    pdfFile = open(path, 'rb')\n",
    "    # create PDFFileReader object to read the file\n",
    "    pdfReader = PdfFileReader(pdfFile)\n",
    "    title = str(pdfReader.getDocumentInfo().title)\n",
    "    # close the PDF file object\n",
    "    pdfFile.close()\n",
    "    return title\n",
    "\n",
    "# to get the paper title from pdf name\n",
    "def get_paper_title2(filepath):\n",
    "    title_without_extension = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    return title_without_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set for your own system depending on where tesseract is installed\n",
    "pytesseract.pytesseract.tesseract_cmd = r'tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_tables = []\n",
    "for file_name in tqdm(pdf_files):\n",
    "    paper_text = get_paper_text(file_name)\n",
    "    key_sentences = sentences_containing_data(paper_text)\n",
    "    # create a table to store the sentences containg the word \"data\"\n",
    "    data_table = pd.DataFrame({\"Sentence\": key_sentences})\n",
    "    data_types = data_table['Sentence'].apply(categrize)\n",
    "    # add a column to store the data type or database\n",
    "    data_table['Data'] = data_types\n",
    "    # filter out sentences without mentioning any data type or database\n",
    "    data_table = data_table[data_table.Data.notnull()]\n",
    "    # add a column to store the paper title\n",
    "    paper_title = get_paper_title2(file_name)    \n",
    "    data_table.insert(0, 'title', paper_title)\n",
    "    paper_tables.append(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tables for different papers\n",
    "large_paper_table = pd.concat(paper_tables, axis=0)\n",
    "large_paper_table = large_paper_table[large_paper_table.Data != '']\n",
    "large_paper_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ef6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint save the table to an excel sheet\n",
    "large_paper_table.to_excel(r'../data/sdg7-coding-auto.xlsx',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
